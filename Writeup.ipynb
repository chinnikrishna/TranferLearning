{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "## Topic: Deep Learning\n",
    "## Project: Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files\n",
    "The following are the files used in the project\n",
    "\n",
    "model.py --- Contains python code for defining, training network in keras and generating a .h5 file\n",
    "\n",
    "drive.py --- Interface to the simulator to run the model from .h5 file. Modified to add similar preprocessing from model.py\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataCollection\n",
    "\n",
    "For collecting data for this project, I used a Steam controller joystick and drove around track for 6 times and collected 5533 samples. Of this data 20% that is 1107 samples is set aside as validation set. Remaining 80% that is 4426 samples are used for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator\n",
    "\n",
    "These samples are fed to a BatchGenerator function which does the following\n",
    "\n",
    "0. Randomly selects batch number of data samples\n",
    "1. Takes the image and resizes it to half of its size\n",
    "2. Takes the center, left and right images and generates their corresponding steering angles\n",
    "3. Flips each image and creates corresponding steering angles\n",
    "\n",
    "Thus each data sample creates 6 images viz., 3 original and 3 flipped.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Architecture\n",
    "Network Architecture is inspired from the network in the paper \"End to End Learning for Self-Driving Cars\" by nVidia. All the layers are initialized by Xavier weight initialization. The network architecture looks as follows\n",
    "<img src =\"Network.png\">\n",
    "Each Fully connected layer has a dropout of 0.15 to generalize learning. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Optimization\n",
    "Adam optimizer is used for optimization of mean square error. Initially I trained for 7 epochs and tested the model in simulator. I found multiple times 7th epoch did not always give the least loss yet the model performed better. So I started saving the model whenever the loss was least. To my suprise I found even the models with bigger loss than the last epoch performed better. So I ran each saved model through simulator and used the best one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results and Reflections\n",
    "This model is able to drive beautifully at the center of the lane for all the track 1. While I had plans to augment data and train model more, I found choosing right weight initialization and right fully connected layers size gave better results than bombarding with more data. So the only augmentation I have done is flipping the frames for generalization to left steering. Overall it was a very satisfying project especially seeing the car drive around on its own :-)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
