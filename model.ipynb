{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import sklearn\n",
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten,Dense,Lambda,Cropping2D,Dropout,Activation\n",
    "from keras.layers.convolutional import Convolution2D \n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSet Ready\n"
     ]
    }
   ],
   "source": [
    "#Lines will store data as follows Center,Left,Right,Angle,Throttle,Break,Speed (Access from 0-6)\n",
    "lines=[]\n",
    "with open(\"../Data/driving_log.csv\") as csvfile:\n",
    "    reader=csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "#Split into sets\n",
    "TrainSamples, ValidationSamples=train_test_split(lines,test_size=0.2)\n",
    "print(\"DataSet Ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4426\n",
      "1107\n"
     ]
    }
   ],
   "source": [
    "print(len(TrainSamples))\n",
    "print(len(ValidationSamples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Collect data from files\n",
    "SteerCorrection=0.25\n",
    "Multiplier=3\n",
    "ImageShape=(160,320,3)\n",
    "#Generators\n",
    "def BatchGenerator(Data,BatchSize=1):\n",
    "    NumSamples=10 #len(Data)\n",
    "    while 1:\n",
    "        random.shuffle(Data)                             #Shuffle Data so images come in random order\n",
    "        for offset in range(0,NumSamples,BatchSize):     #Increment offset by BatchSize\n",
    "            BatchSample=Data[offset:offset+BatchSize]    #Select batch size number of Data samples\n",
    "        TrainFeatures=np.zeros((len(BatchSample)*Multiplier,160,320,3))\n",
    "        TrainLabels=np.zeros(len(BatchSample)*Multiplier)\n",
    "        i=0\n",
    "        for Sample in BatchSample:\n",
    "            #Images\n",
    "            CenterImg=np.asarray(cv2.imread(Sample[0]))\n",
    "            #Might be a bug in simulator. Adding extra whitespace to address for left and right\n",
    "            LeftImg=np.asarray(cv2.imread(Sample[1].strip()))  \n",
    "            RightImg=np.asarray(cv2.imread(Sample[2].strip()))\n",
    "            #Steering Angles\n",
    "            CenterAngle=float(Sample[3])\n",
    "            LeftAngle=(CenterAngle+SteerCorrection)\n",
    "            RightAngle=(CenterAngle-SteerCorrection)\n",
    "            #Image and Angle Accumulation\n",
    "            TrainFeatures[i]=CenterImg\n",
    "            TrainLabels[i]=CenterAngle\n",
    "            i=i+1\n",
    "            TrainFeatures[i]=LeftImg\n",
    "            TrainLabels[i]=LeftAngle\n",
    "            i=i+1\n",
    "            TrainFeatures[i]=RightImg\n",
    "            TrainLabels[i]=RightAngle\n",
    "            yield sklearn.utils.shuffle(TrainFeatures,TrainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Converting into numpy Arrays\n",
    "GeneratedTrain=BatchGenerator(TrainSamples,10)\n",
    "GeneratedVal=BatchGenerator(ValidationSamples,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Network to drive the car\n",
    "FilShape=[5,5,5,3,3]\n",
    "NumFils=[24,36,48,64,64]\n",
    "FCSize=[200,100,10,1]\n",
    "model=Sequential()\n",
    "#PreProcessing\n",
    "model.add(Lambda(lambda x:x/255.0-0.5,input_shape=(160,320,3)))\n",
    "model.add(Cropping2D(cropping=((70,25),(0,0))))\n",
    "#CL1\n",
    "model.add(Convolution2D(NumFils[0],FilShape[0],FilShape[0]))\n",
    "model.add(Activation('relu'))\n",
    "#CL2\n",
    "model.add(Convolution2D(NumFils[1],FilShape[1],FilShape[1]))\n",
    "model.add(Activation('relu'))\n",
    "#CL3\n",
    "model.add(Convolution2D(NumFils[2],FilShape[2],FilShape[2]))\n",
    "model.add(Activation('relu'))\n",
    "#CL4\n",
    "model.add(Convolution2D(NumFils[3],FilShape[3],FilShape[3]))\n",
    "#CL5\n",
    "model.add(Convolution2D(NumFils[4],FilShape[4],FilShape[4]))\n",
    "#Flatten\n",
    "model.add(Flatten())\n",
    "#FC1\n",
    "model.add(Dense(FCSize[0]))\n",
    "#model.add(Dropout(0.5))\n",
    "#FC2\n",
    "model.add(Dense(FCSize[1]))\n",
    "#model.add(Dropout(0.5))\n",
    "#FC3\n",
    "model.add(Dense(FCSize[2]))\n",
    "#model.add(Dropout(0.5))\n",
    "#FC4\n",
    "model.add(Dense(FCSize[3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "4410/4426 [============================>.] - ETA: 0s - loss: 4025.5053"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishna/anaconda3/lib/python3.5/site-packages/keras/engine/training.py:1573: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4440/4426 [==============================] - 55s - loss: 3998.3064 - val_loss: 0.0287\n",
      "Epoch 2/7\n",
      "4440/4426 [==============================] - 47s - loss: 0.0234 - val_loss: 0.0311\n",
      "Epoch 3/7\n",
      " 360/4426 [=>............................] - ETA: 39s - loss: 0.0200"
     ]
    }
   ],
   "source": [
    "#Model\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "model.fit_generator(GeneratedTrain,samples_per_epoch=len(TrainSamples),validation_data=GeneratedVal,\n",
    "                    nb_val_samples=len(ValidationSamples),nb_epoch=7)\n",
    "print(\"Saving Model...\")\n",
    "model.save(\"Model.h5\")\n",
    "print(\"Done...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
